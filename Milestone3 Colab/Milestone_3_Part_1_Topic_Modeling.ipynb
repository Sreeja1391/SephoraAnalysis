{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UODUVCEJAzkG",
        "outputId": "79e0d054-14bb-485e-8498-7abff1556ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from gensim import corpora, models\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.read_csv('/content/reviews_0-250.csv')\n",
        "df1 = pd.read_csv('/content/reviews_1250-end.csv')\n",
        "df2 = pd.read_csv('/content/reviews_250-500.csv')\n",
        "df3 = pd.read_csv('/content/reviews_500-750.csv')\n",
        "df4 = pd.read_csv('/content/reviews_750-1250.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J19jsPr_DlA4",
        "outputId": "f7274ba9-0a28-4bcc-bdf8-97d8c8e6caf0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e7c14bb6833d>:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df0 = pd.read_csv('/content/reviews_0-250.csv')\n",
            "<ipython-input-3-e7c14bb6833d>:2: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df1 = pd.read_csv('/content/reviews_1250-end.csv')\n",
            "<ipython-input-3-e7c14bb6833d>:5: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df4 = pd.read_csv('/content/reviews_750-1250.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = pd.concat([df0, df1, df2, df3, df4], ignore_index=True)"
      ],
      "metadata": {
        "id": "_HE-DyVIO9pe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined['review_text'] = df_combined['review_text'].astype(str)"
      ],
      "metadata": {
        "id": "dvsq3y7CQM7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = df_combined.sample(frac=0.1, random_state=1)"
      ],
      "metadata": {
        "id": "cQ_YXdKPRxHs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df = df_combined.sample(n=1000, random_state=1)"
      ],
      "metadata": {
        "id": "YC0AdsV6R4nh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [text.split() for text in sampled_df['review_text']]"
      ],
      "metadata": {
        "id": "F6a9QCGUSEEN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.parsing.preprocessing import STOPWORDS"
      ],
      "metadata": {
        "id": "Ffd_dzQqTR7j"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')).union(STOPWORDS)\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "xD2wqw8wTT1z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\W', ' ', str(text))\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
        "    text = text.lower()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
        "    return text"
      ],
      "metadata": {
        "id": "emQdKk-OTVsm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_df['cleaned_text'] = sampled_df['review_text'].apply(preprocess_text)\n",
        "texts = [text.split() for text in sampled_df['cleaned_text']]"
      ],
      "metadata": {
        "id": "zK_dS2d0TX48"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim import corpora\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "zq80Fh3ISGSe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.ldamodel import LdaModel"
      ],
      "metadata": {
        "id": "gU4dDmWiTfYX"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_topics = 10\n",
        "passes = 20\n",
        "\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "ldamodel = LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
        "\n",
        "coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3r0DMGwLTkiw",
        "outputId": "82fe3e99-fa27-4458-9d0e-9fb129897d91"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.388778693211581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, topic in ldamodel.show_topics(formatted=True, num_topics=num_topics, num_words=4):\n",
        "    print(f\"Topic #{i+1}: {topic}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pmbYf03HSUA5",
        "outputId": "58cfb201-804a-41a0-b79f-9decae6b6151"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic #1: 0.002*\"point\" + 0.002*\"great\" + 0.001*\"the\" + 0.001*\"non\"\n",
            "\n",
            "Topic #2: 0.006*\"and\" + 0.006*\"this\" + 0.004*\"the\" + 0.004*\"I\"\n",
            "\n",
            "Topic #3: 0.042*\"I\" + 0.032*\"and\" + 0.029*\"the\" + 0.021*\"to\"\n",
            "\n",
            "Topic #4: 0.052*\"I\" + 0.036*\"and\" + 0.026*\"the\" + 0.025*\"my\"\n",
            "\n",
            "Topic #5: 0.032*\"a\" + 0.029*\"and\" + 0.028*\"I\" + 0.026*\"it\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import TfidfModel\n",
        "\n",
        "# 创建TF-IDF模型\n",
        "tfidf = TfidfModel(corpus)\n",
        "corpus_tfidf = tfidf[corpus]\n",
        "\n",
        "# 使用TF-IDF重训练LDA模型\n",
        "ldamodel_tfidf = LdaModel(corpus=corpus_tfidf, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
        "\n",
        "# 评估TF-IDF版本的模型\n",
        "coherence_model_lda_tfidf = CoherenceModel(model=ldamodel_tfidf, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda_tfidf = coherence_model_lda_tfidf.get_coherence()\n",
        "print('\\nCoherence Score with TF-IDF: ', coherence_lda_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hhKzuj4rTtwu",
        "outputId": "8c49b4ac-9fa5-4a24-9a74-7451e9c9d987"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score with TF-IDF:  0.380445940016631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# 计算一致性分数\n",
        "coherence_model_lda = CoherenceModel(model=ldamodel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xym0x1R-SmTy",
        "outputId": "f341fd9e-15e5-40db-a488-303c47c50fcc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Coherence Score:  0.40740606506851185\n"
          ]
        }
      ]
    }
  ]
}